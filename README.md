# Chat-å¬›å¬›
<div align="center">

<img src="./images/logo.png" width="200"/>
  <div align="center">
    <b><font size="5">Chat-å¬›å¬›</font></b>
  </div>

[![license][license-image]][license-url]
[![evaluation][evaluation-image]][evaluation-url]

[ğŸ¤—HuggingFace]() | [![OpenXLab_Model][OpenXLab_Model-image]][OpenXLab_Model-url] | [<img src="./images/modelscope_logo.png" width="20px" /> ModelScope][ModelScope-url]

[![OpenXLab_App][OpenXLab_App-image]][OpenXLab_App-url] | [ğŸ†•Update News](#-news) | [ğŸ¤”Reporting Issues][Issues-url] ä¸¨ [![bilibili][bilibili-image]][bilibili-url]

[English](./README_en-US.md) | [ç®€ä½“ä¸­æ–‡](./README.md)



[license-image]: ./images/license.svg
[evaluation-image]: ./images/compass_support.svg
[OpenXLab_Model-image]: https://cdn-static.openxlab.org.cn/header/openxlab_models.svg
[OpenXLab_App-image]: https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg
[bilibili-image]: https://img.shields.io/badge/AMchat-bilibili-%23fb7299

[license-url]: ./LICENSE
[evaluation-url]: https://github.com/internLM/OpenCompass/
[OpenXLab_Model-url]: https://openxlab.org.cn/models/detail/BYCJS/huanhuan-chat-internlm2-1_8b
[OpenXLab_App-url]: https://openxlab.org.cn/apps/detail/BYCJS/Chat_huanhuan
[bilibili-url]: https://www.bilibili.com/video/â€”â€”/
[ModelScope-url]: https://www.modelscope.cn/models/kmno4zx/huanhuan-chat-internlm2-1_8b/summary
[Issues-url]: https://github.com/KMnO4-zx/xlab-huanhuan/issues

</div>

## ğŸ“ç›®å½•

- [Chat-å¬›å¬›](#chat-å¬›å¬›)
  - [ğŸ“ç›®å½•](#ç›®å½•)
  - [ğŸ“– ç®€ä»‹](#-ç®€ä»‹)
  - [ğŸ”— æ¨¡å‹åŠä½“éªŒåœ°å€](#-æ¨¡å‹åŠä½“éªŒåœ°å€)
  - [ğŸš€ News](#-news)
  - [ğŸ§¾ æ•°æ®é›†](#-æ•°æ®é›†)
  - [ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•](#ï¸-ä½¿ç”¨æ–¹æ³•)
    - [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
    - [é‡æ–°è®­ç»ƒ](#é‡æ–°è®­ç»ƒ)
      - [ç¯å¢ƒæ­å»º](#ç¯å¢ƒæ­å»º)
      - [Transformerså¾®è°ƒ](#transformerså¾®è°ƒ)
      - [XTunerå¾®è°ƒ](#xtunerå¾®è°ƒ)
    - [éƒ¨ç½²](#éƒ¨ç½²)
      - [OpenXLab éƒ¨ç½² Chat-å¬›å¬›](#openxlab-éƒ¨ç½²-chat-å¬›å¬›)
      - [LmDeployéƒ¨ç½²](#lmdeployéƒ¨ç½²)
    - [æµ‹è¯„ä¸é‡åŒ–](#æµ‹è¯„ä¸é‡åŒ–)
      - [OpneCompass è¯„æµ‹](#opnecompass-è¯„æµ‹)
      - [Lmdeploy\&opencompass é‡åŒ–ä»¥åŠé‡åŒ–è¯„æµ‹](#lmdeployopencompass-é‡åŒ–ä»¥åŠé‡åŒ–è¯„æµ‹)
        - [`W4`é‡åŒ–è¯„æµ‹](#w4é‡åŒ–è¯„æµ‹)
        - [`KV Cache`é‡åŒ–è¯„æµ‹](#kv-cacheé‡åŒ–è¯„æµ‹)
  - [ğŸ’• è‡´è°¢](#-è‡´è°¢)
    - [é¡¹ç›®æˆå‘˜](#é¡¹ç›®æˆå‘˜)
    - [ç‰¹åˆ«æ„Ÿè°¢](#ç‰¹åˆ«æ„Ÿè°¢)


## ğŸ“– ç®€ä»‹

> *æ­¤ä»“åº“ä¸»è¦ç”¨äºå°† Chatå¬›å¬› é¡¹ç›®éƒ¨ç½²åˆ° OpenXLab æˆ– ModelScope ã€‚*

&emsp;&emsp;Chat-ç”„å¬›æ˜¯åˆ©ç”¨ã€Šç”„å¬›ä¼ ã€‹å‰§æœ¬ä¸­æ‰€æœ‰å…³äºç”„å¬›çš„å°è¯å’Œè¯­å¥ï¼ŒåŸºäº[InternLM2](https://github.com/InternLM/InternLM.git)è¿›è¡ŒLoRAå¾®è°ƒæˆ–å…¨é‡å¾®è°ƒå¾—åˆ°çš„æ¨¡ä»¿ç”„å¬›è¯­æ°”çš„èŠå¤©è¯­è¨€æ¨¡å‹ã€‚

> ç”„å¬›ï¼Œå°è¯´ã€Šåå®«Â·ç”„å¬›ä¼ ã€‹å’Œç”µè§†å‰§ã€Šç”„å¬›ä¼ ã€‹ä¸­çš„å¥³ä¸€å·ï¼Œæ ¸å¿ƒå¥³ä¸»è§’ã€‚åŸåç”„ç‰å¬›ï¼Œå«Œç‰å­—ä¿—æ°”è€Œæ”¹åç”„å¬›ï¼Œä¸ºæ±‰äººç”„è¿œé“ä¹‹å¥³ï¼Œåè¢«é›æ­£èµå§“é’®ç¥œç¦„æ°ï¼ŒæŠ¬æ——ä¸ºæ»¡æ´²ä¸Šä¸‰æ——ï¼Œè·åâ€œé’®ç¥œç¦„Â·ç”„å¬›â€ã€‚åŒæ²ˆçœ‰åº„ã€å®‰é™µå®¹å‚åŠ é€‰ç§€ï¼Œå› å®¹è²Œé…·ä¼¼çº¯å…ƒçš‡åè€Œè¢«é€‰ä¸­ã€‚å…¥å®«åé¢å¯¹åå¦ƒçš„æ­¥æ­¥ç´§é€¼ï¼Œæ²ˆçœ‰åº„è¢«å†¤ã€å®‰é™µå®¹å˜å¿ƒï¼Œä»åå®‰ä¸€éš…çš„é’æ¶©å°‘å¥³å˜æˆäº†èƒ½å¼•èµ·è¡€é›¨è…¥é£çš„å®«æ–—è€æ‰‹ã€‚é›æ­£å‘ç°å¹´æ°ä¸€æ—çš„é‡å¿ƒåä»¤å…¶çˆ¶ç”„è¿œé“å‰ªé™¤ï¼Œç”„å¬›ä¹Ÿäºåå®«ä¸­ç”¨å¥¹çš„è¿ç¯å·§è®¡å¸®çš‡å¸è§£å†³æ”¿æ•Œï¼Œæ•…è€Œæ·±å¾—é›æ­£çˆ±å¾…ã€‚å‡ ç»å‘¨æŠ˜ï¼Œç»ˆäºæ–—å®äº†åš£å¼ è·‹æ‰ˆçš„åå¦ƒã€‚ç”„å¬›å°å¦ƒæ—¶é­çš‡åå®œä¿®æš—ç®—ï¼Œè¢«çš‡ä¸Šå«Œå¼ƒï¼Œç”Ÿä¸‹å¥³å„¿èƒ§æœˆåå¿ƒç°æ„å†·ï¼Œè‡ªè¯·å‡ºå®«ä¸ºå°¼ã€‚ç„¶å¾—æœéƒ¡ç‹çˆ±æ…•ï¼ŒäºŒäººç›¸çˆ±ï¼Œå¾—çŸ¥æœéƒ¡ç‹æ­»è®¯åç«‹åˆ»è®¾è®¡ä¸é›æ­£å†é‡ï¼Œé£å…‰å›å®«ã€‚æ­¤åç”„çˆ¶å†¤æ¡ˆå¹³åã€ç”„æ°å¤èµ·ï¼Œå¥¹ä¹Ÿç”Ÿä¸‹åŒç”Ÿå­ï¼Œåœ¨æ»´è¡€éªŒäº²ç­‰å„ç§é˜´è°‹ä¸­èº²è¿‡å®œä¿®çš„æš—å®³ï¼Œæœ€åä»¥ç‰ºç‰²è‡ªå·±äº²ç”Ÿèƒå„¿çš„æ–¹å¼æ‰³å€’äº†å¹•åé»‘æ‰‹çš„çš‡åã€‚ä½†é›æ­£åˆé€¼ç”„å¬›æ¯’æ€å…ç¤¼ï¼Œä»¥æµ‹è¯•ç”„å¬›çœŸå¿ƒï¼Œå¹¶è®©å·²ç»ç”Ÿäº§è¿‡å­©å­çš„ç”„å¬›å»å‡†æ ¼å°”å’Œäº²ã€‚ç”„å¬›é‚è§†çš‡å¸ä¸ºæœ€è¯¥æ¯ç­çš„å¯¹è±¡ï¼Œå¤§ç»“å±€é“å°½â€œäººç±»çš„ä¸€åˆ‡äº‰æ–—ï¼Œçš†å› ç»Ÿæ²»è€…çš„ä¸å…¬ä¸ä¹‰è€Œèµ·â€ï¼Œå¹¶æ¯’æ€é›æ­£ã€‚å››é˜¿å“¥å¼˜å†ç™»åŸºä¸ºä¹¾éš†ï¼Œç”„å¬›è¢«å°Šä¸ºåœ£æ¯çš‡å¤ªåï¼Œæƒå€¾æœé‡ï¼Œåœ¨å¦‚æ‡¿ä¼ ä¸­å®‰åº¦æ™šå¹´ã€‚

&emsp;&emsp;Chat-ç”„å¬›ï¼Œå®ç°ä»¥ã€Šç”„å¬›ä¼ ã€‹ä¸ºåˆ‡å…¥ç‚¹ï¼Œæ‰“é€ ä¸€å¥—åŸºäºå°è¯´ã€å‰§æœ¬çš„**ä¸ªæ€§åŒ– AI** å¾®è°ƒå¤§æ¨¡å‹å®Œæ•´æµç¨‹ï¼Œé€šè¿‡æä¾›ä»»ä¸€å°è¯´ã€å‰§æœ¬ï¼ŒæŒ‡å®šäººç‰©è§’è‰²ï¼Œè¿è¡Œæœ¬é¡¹ç›®å®Œæ•´æµç¨‹ï¼Œè®©æ¯ä¸€ä½ç”¨æˆ·éƒ½åŸºäºå¿ƒä»ªçš„å°è¯´ã€å‰§æœ¬æ‰“é€ ä¸€ä¸ªå±äºè‡ªå·±çš„ã€å¥‘åˆè§’è‰²äººè®¾ã€å…·å¤‡é«˜åº¦æ™ºèƒ½çš„ä¸ªæ€§åŒ– AIã€‚

> å…·ä½“å¦‚ä½•å®ç°å…¨æµç¨‹çš„ Character-AI å¾®è°ƒï¼Œå¯å‚è€ƒä¸»ä»“åº“-[huanhuan-chat](https://github.com/KMnO4-zx/huanhuan-chat.git)ã€‚
> 
> å¦‚ä½•å­¦ä¹ å¤§æ¨¡å‹éƒ¨ç½²å’Œå¾®è°ƒè¯·å‚è€ƒï¼š[å¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å—](https://github.com/datawhalechina/self-llm.git) ä»¥åŠ [ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥è¯¾ç¨‹](https://github.com/InternLM/tutorial.git)

&emsp;&emsp;***æ¬¢è¿å¤§å®¶æ¥ç»™[InternLM2](https://github.com/InternLM/InternLM.git)ï¼Œç‚¹ç‚¹starå“¦~***

Chatå¬›å¬›å…¨æµç¨‹å¦‚å›¾æ‰€ç¤ºï¼š

<p align="center">
    <img src="./images/huanhuan_img.png" alt="alt text">
</p>

## ğŸ”— æ¨¡å‹åŠä½“éªŒåœ°å€

***OpenXLab ä½“éªŒåœ°å€ï¼š***

***https://openxlab.org.cn/apps/detail/BYCJS/Chat_huanhuan***

![alt text](./images/huanhuan_chat.png)

***Chat-å¬›å¬› æ¨¡å‹ä¸‹è½½åœ°å€ï¼š***

- ***OpenXLab***

***7B: https://openxlab.org.cn/models/detail/BYCJS/huanhuan-chat-internlm2***

***1.8B: https://openxlab.org.cn/models/detail/BYCJS/huanhuan-chat-internlm2-1_8b***

![alt text](./images/openxlab_model.jpg)

- ***ModelSope***

***7B: https://www.modelscope.cn/models/kmno4zx/huanhuan-chat-internlm2/summary***

***1.8B: https://www.modelscope.cn/models/kmno4zx/huanhuan-chat-internlm2-1_8b/summary***

![Alt text](images/modelscope.png)


## ğŸš€ News

***2æœˆ5æ—¥ï¼Œå®Œæˆ [InternLM2-chat-1_8Bæ¨¡å‹çš„å…¨é‡å¾®è°ƒ](https://www.modelscope.cn/models/kmno4zx/huanhuan-chat-internlm2-1_8b/summary) ï¼Œæ¨¡å‹å·²ä¸Šä¼ ModelScop2ï¼Œå¤§å®¶å¯ä»¥æ¥ä¸‹è½½å“¦~***

***1æœˆ22æ—¥ï¼ŒChat-å¬›å¬›åº”ç”¨åœ¨ OpenXLabï¼Œç´¯è®¡èŠå¤©æ¬¡æ•°å·²è¾¾ 3.64k æ¬¡ï¼Œæ„Ÿè°¢å¤§å®¶çš„æ”¯æŒ~***

***1æœˆ22æ—¥ï¼ŒChat-å¬›å¬›æ¨¡å‹ é­”æ­ ç´¯è®¡ä¸‹è½½ 3107 æ¬¡ï¼***


## ğŸ§¾ æ•°æ®é›†

&emsp;&emsp;Chat-å¬›å¬› æ•°æ®é›†é‡‡ç”¨ã€Šç”„å¬›ä¼ ã€‹å‰§æœ¬ä¸­æ‰€æœ‰å…³äºç”„å¬›çš„å°è¯å’Œè¯­å¥ï¼Œå…±è®¡ 3000 ä½™æ¡ï¼Œæ•°æ®é›†æ ·ä¾‹ï¼š

```text
ç¬¬15å¹•
ï¼ˆç§€å¥³ä»¬åœ¨ç­‰å€™æ®¿é€‰ã€‚ç”„å¬›çœ‹è§äº†çœ‰åº„ï¼Œä¸Šå‰ç›¸è®¤ï¼‰
ç”„å¬›ï¼šçœ‰å§å§ï¼
çœ‰åº„ï¼šå¬›å„¿ï¼Œæ—©å°±å¬è¯´å¦¹å¦¹ä¸­é€‰äº†ï¼Œå¯å°±æ˜¯ä¸€ç›´ä¸å¾—ç©ºè§ä½ ã€‚
ç”„å¬›ï¼ˆå‡‘è¿‘ï¼‰ï¼šæˆ‘å€’å·´ä¸å¾—æ²¡é€‰ä¸Šå‘¢ã€‚å§å§è¿œé“è¿‡æ¥ä¸€å®šå¾ˆè¾›è‹¦å§ã€‚
çœ‰åº„ï¼šåœ¨äº¬é‡Œä¼‘æ¯äº†è¿™äº›æ—¥å­ï¼Œæ—©å·²ç»è°ƒå…»è¿‡æ¥äº†ã€‚
ç”„å¬›ï¼šå¦‚ä»Šä½ ä½åœ¨è‡ªå·±äº¬åŸçš„å®…å­é‡Œï¼Œä¸æ¯”ä»å‰ä½åœ¨å¤–ç¥–å®¶ï¼Œä¸€å¢™ä¹‹éš”ï¼Œè§é¢ä¹Ÿæ–¹ä¾¿ã€‚
çœ‰åº„ï¼šæ˜¯å•Šã€‚å¯æ˜¯æˆ‘æ€»è¿˜æƒ³ç€æˆ‘ä»¬ä¸€èµ·é•¿å¤§çš„æƒ…åˆ†å‘¢ã€‚è¯¶ï¼Ÿå¦¹å¦¹ä»Šæ—¥æ‰“æ‰®å¾—å¥½ç”Ÿç´ å‡€ï¼Œå¯æ˜¯ç»†çœ‹èµ·æ¥è¿˜æ˜¯ä¸ªç¾äººå¯å­ï¼Œæ€ä¹ˆçœ‹éƒ½æ˜¯å¥½çš„ã€‚
ç”„å¬›ï¼šæ²ˆå¤§ç¾äººå·®çŸ£ï¼Œå§å§å‡ºè½å¾—è¿™ä¹ˆæ ‡è‡´ï¼Œçš‡ä¸Šè§è¿‡å¿…å®šä¼šå¿µå¿µä¸å¿˜ã€‚
çœ‰åº„ï¼ˆä¼¸æ‰‹åˆ¶æ­¢ï¼Œå·¦å³çœ‹äº†ä¸‹ï¼‰ï¼šä»Šå¤©ç§€å¥³ä½¼ä½¼è€…ä¼—å¤šï¼Œæˆ‘æœªå¿…ä¸­é€‰ï¼Œè‹¥æ•™æ—äººå¬è§äº†ï¼Œåˆè¦ç”Ÿå‡ºæ˜¯éã€‚
```

&emsp;&emsp;ä½¿ç”¨è„šæœ¬å°†å‰§æœ¬ä¸­å…³äºç”„å¬›çš„å¯¹è¯é›†æŠ½å–å‡ºæ¥ï¼Œä½œä¸ºæ•°æ®é›†ä½¿ç”¨ã€‚

&emsp;&emsp;ä¹Ÿå¯ä»¥ä½¿ç”¨è¿™ä¸ªä»“åº“çš„è„šæœ¬[Extract Dialogue](https://github.com/KMnO4-zx/extract-dialogue.git)ï¼Œè¯·GPTè€å¸ˆæ¥å¸®åŠ©æˆ‘ä»¬ä»å°è¯´ä¸­æŠ½å–å¯¹è¯é›†ã€‚

![Alt text](images/Extract-Dialogue.png)

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹

<!-- ## å¾®è°ƒ -->

1. ä¸‹è½½æ¨¡å‹

<details>
<summary> ä» ModelScope </summary>

å‚è€ƒ [æ¨¡å‹çš„ä¸‹è½½](https://www.modelscope.cn/docs/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E8%BD%BD) ã€‚

```bash
pip install modelscope
```

```python
from modelscope.hub.snapshot_download import snapshot_download
model_dir = snapshot_download('kmno4zx/huanhuan-chat-internlm2', cache_dir='./')
```

</details>


<details>
<summary> ä» OpenXLab </summary>

å‚è€ƒ [ä¸‹è½½æ¨¡å‹](https://openxlab.org.cn/docs/models/%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B.html) ã€‚

```bash
pip install openxlab
```

```python
from openxlab.model import download
download(model_repo='BYCJS/huanhuan-chat-internlm2', 
        model_name='huanhuan-chat-internlm2', output='./')
```

</details>

2. æœ¬åœ°éƒ¨ç½²

```bash
git clone https://github.com/KMnO4-zx/xlab-huanhuan.git
python start.py
```
### é‡æ–°è®­ç»ƒ

#### ç¯å¢ƒæ­å»º

1. clone æœ¬é¡¹ç›®

```bash
git clone https://github.com/KMnO4-zx/xlab-huanhuan.git
cd xlab-huanhuan
```

2. åˆ›å»ºç¯å¢ƒ

```bash
pip install -r requirements.txt
```

>æœ‰ä¸¤ç§å¾®è°ƒæ–¹æ¡ˆï¼Œæˆ‘ä»¬æ›´æ¨èä½¿ç”¨ XTuner è®­ç»ƒï¼Œ XTuner æœ‰å„ä¸ªæ¨¡å‹çš„ä¸€é”®è®­ç»ƒè„šæœ¬ï¼Œç›¸å¯¹ä¾¿æ·ã€‚ä¸”å¯¹ InternLM2 çš„æ”¯æŒåº¦æœ€é«˜ã€‚

#### Transformerså¾®è°ƒ
&emsp;&emsp;ä½¿ç”¨ Transformers çš„ Trainer è¿›è¡Œå¾®è°ƒï¼Œå…·ä½“è„šæœ¬å¯å‚è€ƒ[internlm2-chat-lora](./train/internlm2-chat-lora.ipynb)ï¼Œè¯¥è„šæœ¬åœ¨`train`æ–‡ä»¶å¤¹ä¸‹ã€‚è„šæœ¬å†…æœ‰è¾ƒä¸ºè¯¦ç»†çš„æ³¨é‡Šã€‚

#### XTunerå¾®è°ƒ
&emsp;&emsp;ä½¿ç”¨ XTuner è¿›è¡Œå¾®è°ƒï¼Œå…·ä½“è„šæœ¬å¯å‚è€ƒ[internlm2_chat_7b_qlora_oasst1_e3_copy.py](./train/internlm2_chat_7b_qlora_oasst1_e3_copy.py)ï¼Œè¯¥è„šæœ¬åœ¨`train`æ–‡ä»¶å¤¹ä¸‹ã€‚è„šæœ¬å†…æœ‰è¾ƒä¸ºè¯¦ç»†çš„æ³¨é‡Šã€‚


### éƒ¨ç½²
#### OpenXLab éƒ¨ç½² Chat-å¬›å¬›

&emsp;&emsp;ä»…éœ€è¦ Fork æœ¬ä»“åº“ï¼Œç„¶ååœ¨ OpenXLab ä¸Šåˆ›å»ºä¸€ä¸ªæ–°çš„é¡¹ç›®ï¼Œå°† Fork çš„ä»“åº“ä¸æ–°å»ºçš„é¡¹ç›®å…³è”ï¼Œå³å¯åœ¨ OpenXLab ä¸Šéƒ¨ç½² Chat-å¬›å¬›ã€‚

&emsp;&emsp;***OPenXLab Chatå¬›å¬›  https://openxlab.org.cn/apps/detail/BYCJS/Chat_huanhuan***

![Alt text](images/openxlab.png)

#### LmDeployéƒ¨ç½²

- é¦–å…ˆå®‰è£…LmDeploy

```shell
pip install -U lmdeploy
```

- ç„¶åè½¬æ¢æ¨¡å‹ä¸º`turbomind`æ ¼å¼

> --dst-path: å¯ä»¥æŒ‡å®šè½¬æ¢åçš„æ¨¡å‹å­˜å‚¨ä½ç½®ã€‚

```shell
lmdeploy convert internlm2-chat-7b  è¦è½¬åŒ–çš„æ¨¡å‹åœ°å€ --dst-path è½¬æ¢åçš„æ¨¡å‹åœ°å€
```

- LmDeploy Chat å¯¹è¯

```shell
lmdeploy chat turbomind è½¬æ¢åçš„turbomindæ¨¡å‹åœ°å€
```
### æµ‹è¯„ä¸é‡åŒ–
#### OpneCompass è¯„æµ‹

- å®‰è£… OpenCompass

```shell
git clone https://github.com/open-compass/opencompass
cd opencompass
pip install -e .
```

- ä¸‹è½½è§£å‹æ•°æ®é›†

```shell
cp /share/temp/datasets/OpenCompassData-core-20231110.zip /root/opencompass/
unzip OpenCompassData-core-20231110.zip
```

- è¯„æµ‹å¯åŠ¨ï¼

```shell
python run.py \
    --datasets ceval_gen \
    --hf-path /root/model/huanhuan/kmno4zx/huanhuan-chat-internlm2 \
    --tokenizer-path /root/model/huanhuan/kmno4zx/huanhuan-chat-internlm2 \
    --tokenizer-kwargs padding_side='left' truncation='left'     trust_remote_code=True \
    --model-kwargs device_map='auto' trust_remote_code=True \
    --max-seq-len 2048 \
    --max-out-len 16 \
    --batch-size 2  \
    --num-gpus 1 \
    --debug
```

#### Lmdeploy&opencompass é‡åŒ–ä»¥åŠé‡åŒ–è¯„æµ‹  
##### `W4`é‡åŒ–è¯„æµ‹  

- `W4`é‡åŒ–
```shell
lmdeploy lite auto_awq è¦é‡åŒ–çš„æ¨¡å‹åœ°å€ --work-dir é‡åŒ–åçš„æ¨¡å‹åœ°å€
```
- è½¬åŒ–ä¸º`TurbMind`
```shell
lmdeploy convert internlm2-chat-7b é‡åŒ–åçš„æ¨¡å‹åœ°å€  --model-format awq --group-size 128 --dst-path è½¬æ¢åçš„æ¨¡å‹åœ°å€
```
- è¯„æµ‹`config`ç¼–å†™  
```python
from mmengine.config import read_base
from opencompass.models.turbomind import TurboMindModel

with read_base():
 # choose a list of datasets   
 from .datasets.ceval.ceval_gen import ceval_datasets 
 # and output the results in a choosen format
#  from .summarizers.medium import summarizer

datasets = [*ceval_datasets]

internlm2_chat_7b = dict(
     type=TurboMindModel,
     abbr='internlm2-chat-7b-turbomind',
     path='è½¬æ¢åçš„æ¨¡å‹åœ°å€',
     engine_config=dict(session_len=512,
         max_batch_size=2,
         rope_scaling_factor=1.0),
     gen_config=dict(top_k=1,
         top_p=0.8,
         temperature=1.0,
         max_new_tokens=100),
     max_out_len=100,
     max_seq_len=512,
     batch_size=2,
     concurrency=1,
     #  meta_template=internlm_meta_template,
     run_cfg=dict(num_gpus=1, num_procs=1),
)
models = [internlm2_chat_7b]

```
- è¯„æµ‹å¯åŠ¨ï¼
```shell
python run.py configs/eval_turbomind.py -w æŒ‡å®šç»“æœä¿å­˜è·¯å¾„
```
##### `KV Cache`é‡åŒ–è¯„æµ‹ 
- è½¬æ¢ä¸º`TurbMind`
```shell
lmdeploy convert internlm2-chat-7b  æ¨¡å‹è·¯å¾„ --dst-path è½¬æ¢åæ¨¡å‹è·¯å¾„
```
- è®¡ç®—ä¸è·å¾—é‡åŒ–å‚æ•°
```shell
# è®¡ç®—
lmdeploy lite calibrate æ¨¡å‹è·¯å¾„ --calib-dataset 'ptb' --calib-samples 128 --calib-seqlen 2048 --work-dir å‚æ•°ä¿å­˜è·¯å¾„
# è·å–é‡åŒ–å‚æ•°
lmdeploy lite kv_qparams å‚æ•°ä¿å­˜è·¯å¾„ è½¬æ¢åæ¨¡å‹è·¯å¾„/triton_models/weights/ --num-tp 1
```
- æ›´æ”¹`quant_policy`æ”¹æˆ`4`,æ›´æ”¹ä¸Šè¿°`config`é‡Œé¢çš„è·¯å¾„
- è¯„æµ‹å¯åŠ¨ï¼
```shell
python run.py configs/eval_turbomind.py -w ç»“æœä¿å­˜è·¯å¾„
```
ç»“æœæ–‡ä»¶å¯åœ¨åŒç›®å½•æ–‡ä»¶[results](./results)ä¸­è·å–

## ğŸ’• è‡´è°¢

### é¡¹ç›®æˆå‘˜

- å®‹å¿—å­¦-é¡¹ç›®è´Ÿè´£äºº ï¼ˆDatawhaleæˆå‘˜ ä¹¦ç”ŸÂ·æµ¦è¯­å®æˆ˜è¥åŠ©æ•™ è´Ÿè´£é¡¹ç›®è§„åˆ’ï¼Œæ•°æ®é›†åˆ¶ä½œåŠæ¨¡å‹è®­ç»ƒï¼‰
- è‚–é¸¿å„’ï¼ˆDatawhaleæˆå‘˜ ä¹¦ç”ŸÂ·æµ¦è¯­å®æˆ˜è¥åŠ©æ•™ è´Ÿè´£æ•°æ®é›†æ”¶é›†ã€æ¨¡å‹è¯„æµ‹ï¼‰
- é‚¹é›¨è¡¡ï¼ˆDatawhaleæˆå‘˜ è´Ÿè´£æ•°æ®é›†æ”¶é›†ï¼‰
- æœæ£®ï¼ˆDatawhaleæˆå‘˜ è´Ÿè´£æ•°æ®é›†æ”¶é›†ï¼‰

### ç‰¹åˆ«æ„Ÿè°¢

<div align="center">

***æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ç»„ç»‡çš„ ä¹¦ç”ŸÂ·æµ¦è¯­å®æˆ˜è¥ å­¦ä¹ æ´»åŠ¨~***

***æ„Ÿè°¢ OpenXLab å¯¹é¡¹ç›®éƒ¨ç½²çš„ç®—åŠ›æ”¯æŒ~***

***æ„Ÿè°¢ æµ¦è¯­å°åŠ©æ‰‹ å¯¹é¡¹ç›®çš„æ”¯æŒ~***
</div>
